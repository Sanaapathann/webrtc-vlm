# ğŸš€ Real-time WebRTC + WASM & Server AI Multi-Object Detection

A **dual-mode architecture** that runs **object detection directly in the browser (WASM)** and supports **server-side inference via Python**. This project enables phone-to-laptop live streaming with real-time object detection using ONNX models â€” optimized for **low-resource laptops**.

## ğŸ—ï¸ **Why Dual-Mode Inference?**

### **WASM Mode: Browser-Based Inference (Low-Resource)**
- âœ… **No GPU Required**: Runs on modest laptops (Intel i5, 8GB RAM)
- âœ… **Zero Server Load**: All inference happens in browser
- âœ… **Fast & Private**: No network roundtrip for detections
- âœ… **Optimized**: Quantized ONNX model, 320Ã—240 input, 10 FPS

### **Server Mode: Python Backend (High Accuracy)**
- âœ… **Full AI Stack**: FastAPI + Ultralytics + ONNX Runtime
- âœ… **Scalable**: Can use GPU for higher accuracy models
- âœ… **Extensible**: Ready for YOLOv8, custom models, or cloud deployment

### **Microservices Benefits**
- ğŸ” **Separation of Concerns**: WebRTC in Node.js, AI in Python
- âš™ï¸ **Independent Scaling**: Run AI on GPU server if needed
- ğŸ’¡ **Technology Flexibility**: Best tool for each job
- ğŸ› ï¸ **Easy Maintenance**: Debug and update services independently

---

## ğŸ¯ **What This Project Does**

1. **Phone Camera Stream**: Capture live video from phone via WebRTC
2. **Laptop Receives Stream**: No app install â€” works in Chrome/Safari
3. **Dual Inference Modes**:
   - `MODE=wasm`: ONNX Runtime Web in browser
   - `MODE=server`: Python backend with YOLOv8
4. **Real-time Overlay**: Bounding boxes drawn on video
5. **Benchmarking**: Auto-run 30s test â†’ `metrics.json`

---

## ğŸš€ **Quick Start (One Command)**

### **Prerequisites**
- Docker Desktop (Windows/Mac/Linux)
- Modern browser (Chrome/Firefox/Safari)
- Phone and laptop on same network (or ngrok)

### **Step 1: Clone Repo**
```bash
git clone https://github.com/Sanaapathann/webrtc-vlm.git
cd webrtc-vlm
```

### **Step 2: Start in WASM Mode (Recommended)**
```bash
MODE=wasm ./start.sh
```
or Start in server Mode

```bash
MODE=server ./start.sh
```

### **Step 3: Start with Public URL (Phone on Mobile Hotspot)**
```bash
./start.sh --ngrok
```

### **Step 4: Connect Phone**
1. Open `http://localhost:3000` (or ngrok URL) on **laptop**
2. A QR code appears
3. On **phone**, scan QR with camera
4. Allow camera access
5. See video + bounding boxes on laptop âœ…

---

## ğŸ“± **How to Use (Step by Step)**

### **On Laptop (Receiver)**
1. Run `./start.sh` or `MODE=server ./start.sh`
2. Open `http://localhost:3000` in browser
3. Wait for QR code
4. Watch real-time object detection

### **On Phone (Streamer)**
1. **Scan QR** with phone camera
2. Or manually open the same URL
3. Allow camera access
4. Your video streams to laptop

### **Switch Inference Mode**
```bash
# Low-resource mode (runs in browser)
./start.sh

# Server mode (sends frames to Python)
MODE=server ./start.sh
```

## ğŸ—ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    WebRTC    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phone     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Node.js Server â”‚
â”‚  Camera     â”‚   Signaling  â”‚  (Port 3000)    â”‚
â”‚             â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                                      â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚  Python AI      â”‚
                             â”‚  (Port 8000)    â”‚
                             â”‚  FastAPI + YOLO â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow (WASM Mode)**
1. Phone captures video â†’ WebRTC â†’ Laptop
2. Browser runs ONNX model on video
3. Detections sent via DataChannel
4. Overlay drawn on canvas

### **Data Flow (Server Mode)**
1. Phone â†’ WebRTC â†’ Laptop
2. Frames sent to `http://ai:8000/infer`
3. Python returns detections
4. Sent back via DataChannel â†’ overlay

---

## ğŸ”§ **Installation Options**

### **Option 1: Docker (Recommended)**
```bash
# One command setup
./start.sh

# Or with ngrok
./start.sh --ngrok
```

âœ… Benefits:
- No local dependencies
- Reproducible environment
- Works on any OS
- Auto-QR generation

---

## ğŸ¤– **AI Model Integration**

### **WASM Mode**
- **Model**: Quantized ONNX YOLOv5n
- **Input**: 320Ã—240
- **Inference**: ONNX Runtime Web in browser
- **Latency**: ~320ms median

### **Server Mode**
- **Model**: YOLOv8n (Ultralytics)
- **Input**: 320Ã—240
- **Inference**: FastAPI + ONNX Runtime
- **Extensible**: Add custom models

---

## ğŸ“Š **Performance & Benchmarking**

### **Run Benchmark**
```bash
# Auto-run after 30s in WASM mode
cat metrics.json
```

### **Sample Output**
```json
{
  "processed_fps": 10,
  "p95_e2e_latency_ms": 480,
  "median_e2e_latency_ms": 320,
  "uplink_kbps": 750,
  "downlink_kbps": 200
}
```

### **Performance Tips**
- âœ… Use `MODE=wasm` for low-resource devices
- âœ… Input: 320Ã—240 for balance of quality & speed
- âœ… Frame rate: 10â€“15 FPS to reduce CPU load
- âœ… Use ngrok only when needed

---

## ğŸš¨ **Troubleshooting Guide**

### âŒ Phone Wonâ€™t Connect?
- **Fix**: Use `./start.sh --ngrok` if on different networks
- **Fix**: Ensure both devices use same WiFi
- **Fix**: Disable mobile data on phone

### âŒ QR Code Not Scanning?
- **Fix**: Use `--ngrok` â€” avoids IP/firewall issues
- **Fix**: Refresh page and try again
- **Fix**: Use Google Lens (Android) or native camera (iOS)

### âŒ No Bounding Boxes in Server Mode?
- **Fix**: `MODE=server` is prototype â€” WASM mode is primary
- **Fix**: Ensure `python-multipart` installed
- **Fix**: Check `docker logs webrtc-ai-1`

### âŒ High CPU Usage?
- **Fix**: Use `MODE=wasm` â€” offloads to phone
- **Fix**: Lower resolution or FPS
- **Fix**: Close other apps

---

## ğŸ”§ **Step-by-Step Setup**

### **1. Start the Demo**
```bash
# WASM mode (recommended)
./start.sh

# OR: Server mode
MODE=server ./start.sh

# OR: With public URL
./start.sh --ngrok
```

### **2. Open on Laptop**
- Go to `http://localhost:3000`
- Wait for QR code

### **3. Scan on Phone**
- Use camera to scan QR
- Allow camera access
- Video appears on laptop

### **4. See Results**
- Bounding boxes appear (WASM mode)
- `metrics.json` saved after 30s

---

## ğŸŒ **Network Configuration**

### **Ports Used**
- **3000**: Node.js WebRTC server
- **8000**: Python AI service (internal)
- **4040**: ngrok dashboard (if used)

### **Firewall Tips**
- Allow Docker through firewall
- Port 3000 must be accessible on local network

---

## ğŸ“± **Mobile Device Tips**

### **Browser Compatibility**
- âœ… **iOS**: Safari (iOS 15+)
- âœ… **Android**: Chrome 80+
- âœ… **Desktop**: Chrome, Firefox, Edge

### **Camera Permissions**
- Always allow camera when prompted
- Try incognito mode if blocked

---

## ğŸ“ **Project Structure**
```
webrtc-vlm/
â”œâ”€â”€ ğŸ“ public/                  # Frontend
â”‚   â”œâ”€â”€ ğŸ“„ app.js               # WebRTC + detection logic
â”‚   â”œâ”€â”€ ğŸ“„ wasm_infer.js        # ONNX Runtime Web
â”‚   â”œâ”€â”€ ğŸ“„ index.html           # Receiver UI
â”‚   â””â”€â”€ ğŸ“„ receive.html         # Phone streamer
â”œâ”€â”€ ğŸ“„ server.js                # Node.js signaling server
â”œâ”€â”€ ğŸ“„ server_infer.py          # FastAPI + YOLOv8
â”œâ”€â”€ ğŸ“„ Dockerfile               # Node.js container
â”œâ”€â”€ ğŸ“„ Dockerfile.ai            # Python container
â”œâ”€â”€ ğŸ“„ docker-compose.yml       # Service orchestration
â”œâ”€â”€ ğŸ“„ start.sh                 # Startup script
â”œâ”€â”€ ğŸ“„ metrics.json             # Auto-generated
â”œâ”€â”€ ğŸ“„ report.md                # Design report
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python deps
â””â”€â”€ ğŸ“„ README.md                # This file
```

---

## ğŸ¯ **Use Cases**

### **Education & Remote Help**
- Students share workspace
- Remote debugging or guidance

### **Low-Resource Devices**
- Runs on old laptops, no GPU
- Ideal for developing regions

### **Privacy-Sensitive Apps**
- WASM mode: no data leaves browser
- No cloud costs or API keys

---

## ğŸ”® **Future Enhancements**

### **Planned Features**
- ğŸš€ Move WASM to Web Worker
- ğŸ”„ Dynamic input resolution
- ğŸ“ˆ Real-time FPS/latency graph
- ğŸ’¾ Save detection history

### **AI Improvements**
- ğŸ§  Support for custom ONNX models
- ğŸ¯ Track objects across frames
- ğŸ”Š Add audio streaming

---

## ğŸ¤ **Contributing**

### **How to Contribute**
1. Fork the repo
2. Create feature branch
3. Test changes
4. Submit PR

### **Development Setup**
```bash
npm install
pip install -r requirements.txt
```

---

## ğŸ“ **Support & Community**

### **Getting Help**
- **GitHub Issues**: Bug reports
- **README**: Clear setup guide
- **Loom Video**: 1-min demo

---

## ğŸ“„ **License**
MIT License â€” see [LICENSE](LICENSE)

---

## ğŸ™ **Acknowledgments**
- **ONNX Runtime**: For WASM inference
- **Ultralytics**: YOLO models
- **FastAPI**: Modern Python backend
- **WebRTC**: Real-time communication
- **ngrok**: Easy public access

---

## ğŸŒŸ **Star History**
If this project helps you, please give it a â­!

---

**Built with â¤ï¸ by Sana Pathan**  
*Demonstrating real-time AI on a modest laptop*